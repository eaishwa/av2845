{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AML HW-4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20000 entries, 93004 to 69344\n",
      "Data columns (total 2 columns):\n",
      "body       20000 non-null object\n",
      "REMOVED    20000 non-null bool\n",
      "dtypes: bool(1), object(1)\n",
      "memory usage: 332.0+ KB\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('rscience-popular-comment-removal/reddit_200k_train.csv',\n",
    "                    encoding='iso-8859-1')\n",
    "train = train[['body','REMOVED']]\n",
    "train = train.sample(n=20000)\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4000 entries, 36500 to 13330\n",
      "Data columns (total 2 columns):\n",
      "body       4000 non-null object\n",
      "REMOVED    4000 non-null bool\n",
      "dtypes: bool(1), object(1)\n",
      "memory usage: 66.4+ KB\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('rscience-popular-comment-removal/reddit_200k_test.csv',\n",
    "                   encoding='iso-8859-1')\n",
    "test = test[['body','REMOVED']]\n",
    "test = test.sample(n=4000)\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "fig , ax = plt.subplots(figsize=(6,4))\n",
    "sns.countplot(x='REMOVED', data=train)\n",
    "plt.title(\"Count of applied\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above plot, we can observe that the dataset doesn't have a remarkabke imbalance. It is pretty fair. For this homework, we choose roc_auc as our scoring parameter. It is a robust measure classification performance. Also, we do not split the train data into test/train, we train the models on the whole train data and test on the test data provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code snippet collects a list of stop words from the nltk API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/alex/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a baseline model, we present countvectorizer with default parameters and fit a logistic regression model on the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/anaconda3/envs/py37/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "with warnings.catch_warnings():\n",
    "    vect = CountVectorizer()\n",
    "    X_train = vect.fit_transform(train['body'])\n",
    "    lr = LogisticRegression().fit(X_train, train['REMOVED'])\n",
    "    y_pred = lr.predict(vect.transform(test['body']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6534125674057227"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print(\"ROC AUC score on test data for the baseline model:\")\n",
    "roc_auc_score(test['REMOVED'].values.ravel(),y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above score is the baseline roc_auc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# lr.coef_.tolist()[0]\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.DataFrame({'features':vect.get_feature_names(),'coeffs':lr.coef_.tolist()[0]})\n",
    "df = df.reindex(df.coeffs.abs().sort_values(ascending = False).index)\n",
    "plt.bar(df.iloc[:10,0],df.iloc[:10,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing punctuations/ stop words still hurt the model performance. This can be inferred as such words being a key differentiator between bad and good comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF Vectorization (default parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = train['body']\n",
    "data_y = train['REMOVED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF vectorizer with default parameters with GridSearchCV on regularization parameter gives the best parameter and roc auc validation score:\n",
      "{'logisticregression__C': 1}\n",
      "0.7339112649110733\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    param_lr = {'logisticregression__C': [0.001, 0.01, 0.1, 1, 10, 100] }\n",
    "    gs_lr = GridSearchCV(estimator=make_pipeline(TfidfVectorizer(),\n",
    "                                                 LogisticRegression()),\n",
    "                         param_grid=param_lr,scoring=\"roc_auc\")\n",
    "    gs_lr.fit(data_x,data_y)\n",
    "    print(\"TFIDF vectorizer with default parameters with GridSearchCV on \\\n",
    "        regularization parameter gives the best parameter and roc auc validation score:\")\n",
    "    print(gs_lr.best_params_)\n",
    "    print(gs_lr.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test score for the above model is :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6368888956870992"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "y_pred = gs_lr.best_estimator_.predict(test['body'])\n",
    "print(\"The test score for the above model is :\")\n",
    "roc_auc_score(test['REMOVED'], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorizer (bi-grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logisticregression__C': 0.1}\n",
      "0.7286419756419035\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    param_lr = {'logisticregression__C': [0.001, 0.01, 0.1, 1, 10, 100] }\n",
    "    gs_lr = GridSearchCV(estimator=make_pipeline(CountVectorizer(ngram_range=(1,2)),\n",
    "                                                 LogisticRegression()),\n",
    "                         param_grid=param_lr,scoring=\"roc_auc\")\n",
    "    gs_lr.fit(data_x,data_y)\n",
    "    print(gs_lr.best_params_)\n",
    "    print(gs_lr.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above is the count vectorizer with bi-grams included and GridSearchCV on regularization parameter gives the best parameter and roc auc validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.668593654478653"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = gs_lr.best_estimator_.predict(test['body'])\n",
    "roc_auc_score(test['REMOVED'],y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above is the test roc auc for the same model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count vectorization with Normalization and Grid Search on min_df and ngram_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'countvectorizer__min_df': 2, 'countvectorizer__ngram_range': (2, 2), 'logisticregression__C': 1}\n",
      "0.6870029111181523\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    param_grid = {\"logisticregression__C\": [10, 1, 0.1],\n",
    "                  \"countvectorizer__ngram_range\": [(2, 2), (2, 3)],\n",
    "                  \"countvectorizer__min_df\": [1, 2, 3],\n",
    "                 }\n",
    "    grid = GridSearchCV(make_pipeline(CountVectorizer(), Normalizer(), \n",
    "                                      LogisticRegression(),\n",
    "                                      memory=\"cache_folder\"),\n",
    "                        param_grid=param_grid, cv=3, scoring=\"roc_auc\"\n",
    "                       )\n",
    "    grid.fit(text_train,y_train)\n",
    "    print(grid.best_params_)\n",
    "    print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.668593654478653"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = gs_lr.best_estimator_.predict(test['body'])\n",
    "roc_auc_score(test['REMOVED'],y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The above model is generalizes very well on different datasets. Most importantly, it doesn't overfit the training data. This is an important observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorization with character-grams that appear in at least 2 documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    param_grid = {\"logisticregression__C\": [10, 1, 0.1, 0.01]}\n",
    "    grid = GridSearchCV(make_pipeline(CountVectorizer(analyzer=\"char_wb\", \n",
    "                                                      ngram_range=(1, 2), \n",
    "                                                      min_df=2), \n",
    "                                      Normalizer(), LogisticRegression(),\n",
    "                                      memory=\"cache_folder\"),\n",
    "                        param_grid=param_grid, cv=3, scoring=\"roc_auc\"\n",
    "                       )\n",
    "    grid.fit(text_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logisticregression__C': 10}\n",
      "0.7360287580783794\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.668593654478653"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = gs_lr.best_estimator_.predict(test['body'])\n",
    "roc_auc_score(test['REMOVED'],y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove punctuation, numbers, stopwords, and one letter words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new = train.copy()\n",
    "\n",
    "train_new['body'] = train_new['body'].str.replace(r'[^\\w\\s]+', '')\n",
    "train_new['body'] = train_new['body'].str.replace(r'\\d+', '')\n",
    "train_new['body'] = train_new.apply(lambda x: ' '.join([item for \\\n",
    "    item in x['body'].split() if item not in stop and len(item) > 1]), axis=1)\n",
    "\n",
    "test_new = test.copy()\n",
    "\n",
    "test_new['body'] = test_new['body'].str.replace(r'[^\\w\\s]+', '')\n",
    "test_new['body'] = test_new['body'].str.replace(r'\\d+', '')\n",
    "test_new['body'] = test_new.apply(lambda x: ' '.join([item for \\\n",
    "    item in x['body'].split() if item not in stop and len(item) > 1]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following models fit the preprocessed data as above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF Vectorization + Grid Search (default parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logisticregression__C': 1, 'tfidfvectorizer__ngram_range': (2, 3)}\n",
      "0.7350216478366282\n"
     ]
    }
   ],
   "source": [
    "data_x = train_new['body']\n",
    "data_y = train['REMOVED']\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    param_lr = {'logisticregression__C': [0.1, 1, 10],\n",
    "                'tfidfvectorizer__ngram_range': [(2,2), (2,3), (3,3)]}\n",
    "    gs_lr = GridSearchCV(estimator=make_pipeline(TfidfVectorizer(min_df=2, \n",
    "                                                                 analyzer='char_wb'),\n",
    "                                                 LogisticRegression()),\n",
    "                         param_grid=param_lr,scoring=\"roc_auc\")\n",
    "    gs_lr.fit(data_x,data_y)\n",
    "    print(gs_lr.best_params_)\n",
    "    print(gs_lr.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6600407364591309"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = gs_lr.best_estimator_.predict(test['body'])\n",
    "roc_auc_score(test['REMOVED'], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tfidf Vectorization with l1 normalization for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logisticregression__C': 10, 'tfidfvectorizer__ngram_range': (2, 2)}\n",
      "0.6007656159548914\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "data_x = train_new['body']\n",
    "data_y = train['REMOVED']\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    param_grid = {\"logisticregression__C\": [10, 1, 0.1],\n",
    "                  \"tfidfvectorizer__ngram_range\": [(2, 2), (2, 3), (3, 3)],\n",
    "                 }\n",
    "    grid = GridSearchCV(make_pipeline(TfidfVectorizer(min_df=2), \n",
    "                                      Normalizer(norm='l1'), LogisticRegression(),\n",
    "                                      memory=\"cache_folder\"),\n",
    "                        param_grid=param_grid, cv=3, scoring=\"roc_auc\"\n",
    "                       )\n",
    "    grid.fit(data_x, data_y)\n",
    "    print(grid.best_params_)\n",
    "    print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5579356682125239"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = grid.best_estimator_.predict(test['body'])\n",
    "roc_auc_score(test['REMOVED'], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are getting poor results after removing stop words and punctuations. That makes sense in a way that unwanted comments tend to contain many stop words or irrelavant punctuations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parts Of Speech Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this method, we generate the part of speech for every word in the dataset and run a bag of words model on that transformed dataset with parts of speech as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/alex/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/alex/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000,)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "df = []\n",
    "for index,row in train['body'].iteritems():\n",
    "    all_rows = []\n",
    "    tokens = nltk.word_tokenize(row)\n",
    "    pos = nltk.pos_tag(tokens)\n",
    "    for tup in pos:\n",
    "        all_rows.append(tup[1])\n",
    "    df.append(all_rows)\n",
    "\n",
    "df = np.array(df)\n",
    "pos_train = []\n",
    "for r in df:\n",
    "    string = ' '.join(r)\n",
    "    pos_train.append(string)\n",
    "pos_train = np.array(pos_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,)\n"
     ]
    }
   ],
   "source": [
    "df = []\n",
    "for index,row in test['body'].iteritems():\n",
    "    all_rows = []\n",
    "    tokens = nltk.word_tokenize(row)\n",
    "    pos = nltk.pos_tag(tokens)\n",
    "    for tup in pos:\n",
    "        all_rows.append(tup[1])\n",
    "    df.append(all_rows)\n",
    "\n",
    "df = np.array(df)\n",
    "pos_test = []\n",
    "for r in df:\n",
    "    string = ' '.join(r)\n",
    "    pos_test.append(string)\n",
    "pos_test = np.array(pos_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logisticregression__C': 0.001}\n",
      "0.6596571286812043\n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    param_grid = {\"logisticregression__C\": [0.0001,0.001,10, 1, 0.1,1000]}\n",
    "    grid = GridSearchCV(make_pipeline(CountVectorizer(min_df=2), \n",
    "                                      LogisticRegression(),\n",
    "                                      memory=\"cache_folder\"),\n",
    "                        param_grid=param_grid, cv=3, scoring=\"roc_auc\"\n",
    "                       )\n",
    "    grid.fit(pos_train, train['REMOVED'])\n",
    "    print(grid.best_params_)\n",
    "    print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = grid.best_estimator_.predict(test['body'])\n",
    "roc_auc_score(test['REMOVED'], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POS tagging performs miserably bad and hence we discard this model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Deriving Other Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex\n",
    "\n",
    "def swear_words(row):\n",
    "    sent = row['sent'].lower()\n",
    "    matches = [r'fuck', r'shit', r'ass', r'bitch', r'dick']\n",
    "    total = 0\n",
    "    \n",
    "    for pattern in matches:\n",
    "        total += len(regex.findall(pattern, sent))\n",
    "    \n",
    "    return total\n",
    "    \n",
    "def strong_words(row):\n",
    "    sent = row['sent'].lower()\n",
    "    matches = [r'dumb', r'idiot', r'moron', r'stupid', r'suck', r'damn', r'hell']\n",
    "    total = 0\n",
    "    \n",
    "    for pattern in matches:\n",
    "        total += len(regex.findall(pattern, sent))\n",
    "    \n",
    "    return total\n",
    "\n",
    "def html_tags(row):\n",
    "    return len(regex.findall(r'</?\\w+>', row['sent']))\n",
    "\n",
    "def compute_wl(row):\n",
    "    avgs_word = [len(x) for x in row['sent'].split()]\n",
    "    return sum(avgs_word) / len(avgs_word) if len(avgs_word) != 0 else 0    \n",
    "\n",
    "def feature_adder(data):\n",
    "    data_df = pd.DataFrame({'index': data.index, 'sent': data.values})\n",
    "    \n",
    "    data_df['sent'] = data_df['sent'].str.replace(r'\\d+', '')\n",
    "    data_df['sent'] = data_df.apply(lambda x: ' '.join([item for \\\n",
    "        item in x['sent'].split() if item not in stop and len(item) > 1]), axis=1)\n",
    "    \n",
    "    data_df['length'] = data_df['sent'].apply(len)\n",
    "    data_df['num_words'] = data_df['sent'].str.split().apply(len)\n",
    "    data_df['avg_word_length'] = data_df.apply(lambda row: compute_wl(row), axis=1)\n",
    "    data_df['word_length_ratio'] = data_df['num_words'] / data_df['length']\n",
    "    data_df['num_caps'] = data_df.apply(lambda row: \\\n",
    "        sum(1 for c in row['sent'] if c.isupper()), axis=1)\n",
    "    data_df['num_exclamations'] = data_df.apply(lambda row: \\\n",
    "        len(regex.findall(r'!', row['sent'])), axis=1)\n",
    "    data_df['num_swear_words'] = data_df.apply(lambda row: swear_words(row), axis=1)\n",
    "    data_df['num_strong_words'] = data_df.apply(lambda row: \\\n",
    "        len(regex.findall(r'</?\\w+', row['sent'])), axis=1)\n",
    "    \n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new features added are:\n",
    "\n",
    "length, number of words, average word length, word length ratio, number of capital letters, number of exclamations, number of swear words and number of strong words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new_derived = feature_adder(train['body'])\n",
    "test_new_derived = feature_adder(test['body'])\n",
    "\n",
    "train_new_derived['REMOVED'] = train['REMOVED'].reset_index(drop=True)\n",
    "test_new_derived['REMOVED'] = test['REMOVED'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new_derived_x = train_new_derived.drop(columns=['index', 'sent', 'REMOVED'])\n",
    "train_new_derived_y = train_new_derived['REMOVED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_new_derived_x = test_new_derived.drop(columns=['index', 'sent', 'REMOVED'])\n",
    "test_new_derived_y = test_new_derived['REMOVED']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With just new features (including polynomial features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1}\n",
      "0.6648255850538843\n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    param_grid = {\"C\": [10, 1, 0.1]}\n",
    "    \n",
    "    grid = GridSearchCV(LogisticRegression(), param_grid=param_grid, \n",
    "                        cv=3, scoring=\"roc_auc\")\n",
    "    grid.fit(train_new_derived_x, train_new_derived_y)\n",
    "    print(grid.best_params_)\n",
    "    print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5433991053571894"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = grid.best_estimator_.predict(test_new_derived_x)\n",
    "roc_auc_score(test_new_derived_y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map features to polynomial space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1}\n",
      "0.6700205293901936\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "data_poly_x = PolynomialFeatures().fit(train_new_derived_x)\n",
    "data_poly_x_train = data_poly_x.transform(train_new_derived_x)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    param_grid = {\"C\": [10, 1, 0.1]}\n",
    "    \n",
    "    grid = GridSearchCV(LogisticRegression(), param_grid=param_grid, \n",
    "                        cv=3, scoring=\"roc_auc\")\n",
    "    grid.fit(data_poly_x_train, train_new_derived_y)\n",
    "    print(grid.best_params_)\n",
    "    print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5004751621121957"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_poly_x_test = data_poly_x.transform(test_new_derived_x)\n",
    "y_pred = grid.best_estimator_.predict(data_poly_x_test)\n",
    "roc_auc_score(test_new_derived_y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we conclude that the new features derived do not convey any information about the target variable. The models discussed prior to this are better than this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used nltk package to lemmatize words in the dataset and apply count vectorizer on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/alex/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "df = []\n",
    "for index,row in train['body'].iteritems():\n",
    "    all_tokens = []\n",
    "    tokens = nltk.word_tokenize(row)\n",
    "    for token in tokens:\n",
    "        all_tokens.append(wnl.lemmatize(token))\n",
    "    df.append(all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000,)\n"
     ]
    }
   ],
   "source": [
    "mydf = []\n",
    "for r in df:\n",
    "    string = ' '.join(r)\n",
    "    mydf.append(string)\n",
    "mydf = np.array(mydf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logisticregression__C': 0.1}\n",
      "0.7304707288480369\n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    param_grid = {\"logisticregression__C\": [0.0001,0.001,10, 1, 0.1,1000]}\n",
    "    grid = GridSearchCV(make_pipeline(CountVectorizer(min_df=2), \n",
    "                                      LogisticRegression(),\n",
    "                                      memory=\"cache_folder\"),\n",
    "                        param_grid=param_grid, cv=3, scoring=\"roc_auc\"\n",
    "                       )\n",
    "    grid.fit(mydf, train['REMOVED'])\n",
    "    print(\"Cross validation best parameter and training score:\")\n",
    "    print(grid.best_params_)\n",
    "    print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,)\n"
     ]
    }
   ],
   "source": [
    "df = []\n",
    "for index,row in test['body'].iteritems():\n",
    "    all_tokens = []\n",
    "    tokens = nltk.word_tokenize(row)\n",
    "    for token in tokens:\n",
    "        all_tokens.append(wnl.lemmatize(token))\n",
    "    df.append(all_tokens)\n",
    "    \n",
    "lemm_test = []\n",
    "for r in df:\n",
    "    string = ' '.join(r)\n",
    "    lemm_test.append(string)\n",
    "lemm_test = np.array(lemm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6360010630566989"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = grid.best_estimator_.predict(lemm_test)\n",
    "print(\"Test score on lemmatized dataset:\")\n",
    "roc_auc_score(test['REMOVED'], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2vec representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin',\n",
    "                                                        binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2vec(text):\n",
    "    vec = []\n",
    "    for index, doc in text.iteritems():\n",
    "        mod_val = []\n",
    "        for word in doc.split(' '):\n",
    "            if word in stop or word.isdigit():\n",
    "                continue\n",
    "            try:\n",
    "                mod_val.append(model[word])\n",
    "            except:\n",
    "                continue\n",
    "        if not mod_val:\n",
    "            vec.append([0]*300)\n",
    "        else:\n",
    "            vec.append(np.mean(np.array(mod_val), axis=0).tolist())\n",
    "    return np.array(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = convert2vec(train['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1}\n",
      "0.6993820442773924\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    param_lr = {'C': [0.001, 0.01, 0.1, 1, 10, 100] }\n",
    "    gs_lr = GridSearchCV(estimator=LogisticRegression(),\n",
    "                         param_grid=param_lr,scoring=\"roc_auc\")\n",
    "    gs_lr.fit(vec, train['REMOVED'])\n",
    "    print(gs_lr.best_params_)\n",
    "    print(gs_lr.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5977853033322207"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "y_pred = gs_lr.best_estimator_.predict(convert2vec(test['body']))\n",
    "roc_auc_score(test['REMOVED'],y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word2vec is giving bad results possibly because it is a pre-trained model on a different corpus. It is creating a vector space where context of words is captured in the documents by which they are trained. So, this pretrained model may not hold good for our train/test data. This possibly explains the poor roc auc scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast text representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim.models import KeyedVectors\n",
    "wv_from_text = KeyedVectors.load_word2vec_format(\\\n",
    "    datapath('/Users/alex/Desktop/AppliedML/homework-4-alk2225_av2845/wiki-news-300d-1M.vec'), binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2vec(text):\n",
    "    vec = []\n",
    "    for index, doc in text.iteritems():\n",
    "        mod_val = []\n",
    "        for word in doc.split(' '):\n",
    "            if word in stop or word.isdigit():\n",
    "                continue\n",
    "            try:\n",
    "                mod_val.append(wv_from_text[word])\n",
    "            except:\n",
    "                continue\n",
    "        if not mod_val:\n",
    "            vec.append([0]*300)\n",
    "        else:\n",
    "            vec.append(np.mean(np.array(mod_val), axis=0).tolist())\n",
    "    return np.array(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = convert2vec(train['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1}\n",
      "0.6977924699550933\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    param_lr = {'C': [0.001, 0.01, 0.1, 1, 10, 100] }\n",
    "    gs_lr = GridSearchCV(estimator=LogisticRegression(),\n",
    "                         param_grid=param_lr,scoring=\"roc_auc\")\n",
    "    gs_lr.fit(vec, train['REMOVED'])\n",
    "    print(gs_lr.best_params_)\n",
    "    print(gs_lr.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5002195385923033"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = gs_lr.best_estimator_.predict(convert2vec(test['body']))\n",
    "roc_auc_score(test['REMOVED'],y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same explanation for word2vec holds for fasttext too!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our best model with all the above trials is as follows:\n",
    "{'logisticregression__C': 1, 'tfidfvectorizer__ngram_range': (2, 3)}\n",
    "Cross validation score - 0.7350216478366282\n",
    "Test score - 0.66\n",
    "\n",
    "This is the most general model:\n",
    "{'countvectorizer__min_df': 2, 'countvectorizer__ngram_range': (2, 2), 'logisticregression__C': 1}\n",
    "cross validation score - 0.6870029111181523\n",
    "Test score - 0.668593654478653\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
